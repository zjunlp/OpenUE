{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 中文三元组联合抽取\n",
    "\n",
    "## 介绍\n",
    "\n",
    "在这个notebook中我们将使用openue库代码来训练我们自己的三元组联合抽取，使用的基础模型是`bert-base-chinese`，训练分为两步，首先训练关系分类模型，其次训练实体抽取模型。之后联合验证。\n",
    "\n",
    "## 数据集\n",
    "\n",
    "在这个数据集中，使用ske数据集，具体例子如下。我们使用代码来读取`train.json`来分析一下数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postag: [{'word': '如何', 'pos': 'r'}, {'word': '演', 'pos': 'v'}, {'word': '好', 'pos': 'a'}, {'word': '自己', 'pos': 'r'}, {'word': '的', 'pos': 'u'}, {'word': '角色', 'pos': 'n'}, {'word': '，', 'pos': 'w'}, {'word': '请', 'pos': 'v'}, {'word': '读', 'pos': 'v'}, {'word': '《', 'pos': 'w'}, {'word': '演员自我修养', 'pos': 'nw'}, {'word': '》', 'pos': 'w'}, {'word': '《', 'pos': 'w'}, {'word': '喜剧之王', 'pos': 'nw'}, {'word': '》', 'pos': 'w'}, {'word': '周星驰', 'pos': 'nr'}, {'word': '崛起', 'pos': 'v'}, {'word': '于', 'pos': 'p'}, {'word': '穷困潦倒', 'pos': 'a'}, {'word': '之中', 'pos': 'f'}, {'word': '的', 'pos': 'u'}, {'word': '独门', 'pos': 'n'}, {'word': '秘笈', 'pos': 'n'}]\n",
      "text: 如何演好自己的角色，请读《演员自我修养》《喜剧之王》周星驰崛起于穷困潦倒之中的独门秘笈\n",
      "spo_list: [{'predicate': '主演', 'object_type': '人物', 'subject_type': '影视作品', 'object': '周星驰', 'subject': '喜剧之王'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../dataset/ske/train.json\", \"r\") as file:\n",
    "    for line in file.readlines():\n",
    "        example = json.loads(line)\n",
    "        break\n",
    "for k, v in example.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练\n",
    "\n",
    "## `seq model`关系分类模型\n",
    "\n",
    "如我们的模型图所示，我们需要先训练一个关系分类模型，识别出句子中实体的属性。也就是模型图中下方位置的关系类型识别模块，用来识别出句子中存在的关系。\n",
    "\n",
    "我们训练和验证模型使用的都是同一份代码，区别仅为`config`的设置不同，config具体的文件目录在`./config`下。\n",
    "<div  align=\"center\">\n",
    "    <img src=\"./imgs/architecture.png\" width = \"600\" height = \"400\" alt=\"图片名称\" align=center />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import openue.lit_models as lit_models\n",
    "import yaml\n",
    "import time\n",
    "from transformers import AutoConfig\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置一些参数和动态调用包\n",
    "def _import_class(module_and_class_name: str) -> type:\n",
    "    module_name, class_name = module_and_class_name.rsplit(\".\", 1)\n",
    "    module = importlib.import_module(module_name)\n",
    "    class_ = getattr(module, class_name)\n",
    "\t\n",
    "    return class_\n",
    "\n",
    "\n",
    "def _setup_parser():\n",
    "    \"\"\"Set up Python's ArgumentParser with data, model, trainer, and other arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(add_help=False)\n",
    "\n",
    "    # Add Trainer specific arguments, such as --max_epochs, --gpus, --precision\n",
    "    # trainer_parser = pl.Trainer.add_argparse_args(parser)\n",
    "    # trainer_parser._action_groups[1].title = \"Trainer Args\"  # pylint: disable=protected-access\n",
    "    # parser = argparse.ArgumentParser(add_help=False, parents=[trainer_parser])\n",
    "\n",
    "    # Basic arguments\n",
    "    parser.add_argument(\"--wandb\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--seed\", type=int, default=42)\n",
    "    parser.add_argument(\"--litmodel_class\", type=str, default=\"SEQLitModel\")\n",
    "    parser.add_argument(\"--data_class\", type=str, default=\"REDataset\")\n",
    "    parser.add_argument(\"--model_class\", type=str, default=\"BertForRelationClassification\")\n",
    "    parser.add_argument(\"--load_checkpoint\", type=str, default=None)\n",
    "\n",
    "    # Get the data and model classes, so that we can add their specific arguments\n",
    "    temp_args, _ = parser.parse_known_args()\n",
    "    data_class = _import_class(f\"openue.data.{temp_args.data_class}\")\n",
    "    model_class = _import_class(f\"openue.models.{temp_args.model_class}\")\n",
    "\n",
    "    # Get data, model, and LitModel specific arguments\n",
    "    data_group = parser.add_argument_group(\"Data Args\")\n",
    "    data_class.add_to_argparse(data_group)\n",
    "\n",
    "    model_group = parser.add_argument_group(\"Model Args\")\n",
    "    model_class.add_to_argparse(model_group)\n",
    "\n",
    "    lit_model_group = parser.add_argument_group(\"LitModel Args\")\n",
    "    lit_models.BaseLitModel.add_to_argparse(lit_model_group)\n",
    "\n",
    "    parser.add_argument(\"--help\", \"-h\", action=\"help\")\n",
    "    return parser\n",
    "\n",
    "def _save_model(litmodel, tokenizer, path):\n",
    "    os.system(f\"mkdir -p {path}\")\n",
    "    litmodel.model.save_pretrained(path)\n",
    "    tokenizer.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c196a273170a>:6: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  opt = yaml.load(open(path))\n",
      "10/09/2021 13:55:49 - INFO - openue.data.data_module -   add total special tokens: 50 \n",
      " ['[relation0]', '[relation1]', '[relation2]', '[relation3]', '[relation4]', '[relation5]', '[relation6]', '[relation7]', '[relation8]', '[relation9]', '[relation10]', '[relation11]', '[relation12]', '[relation13]', '[relation14]', '[relation15]', '[relation16]', '[relation17]', '[relation18]', '[relation19]', '[relation20]', '[relation21]', '[relation22]', '[relation23]', '[relation24]', '[relation25]', '[relation26]', '[relation27]', '[relation28]', '[relation29]', '[relation30]', '[relation31]', '[relation32]', '[relation33]', '[relation34]', '[relation35]', '[relation36]', '[relation37]', '[relation38]', '[relation39]', '[relation40]', '[relation41]', '[relation42]', '[relation43]', '[relation44]', '[relation45]', '[relation46]', '[relation47]', '[relation48]', '[relation49]']\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForRelationClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForRelationClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForRelationClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForRelationClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['relation_classification.weight', 'relation_classification.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "10/09/2021 13:56:02 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_train_BertTokenizerFast_seq\n",
      "10/09/2021 13:56:14 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_dev_BertTokenizerFast_seq\n",
      "10/09/2021 13:56:14 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_test_BertTokenizerFast_seq\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type                          | Params\n",
      "----------------------------------------------------------\n",
      "0 | loss_fn | BCEWithLogitsLoss             | 0     \n",
      "1 | model   | BertForRelationClassification | 102 M \n",
      "----------------------------------------------------------\n",
      "102 M     Trainable params\n",
      "0         Non-trainable params\n",
      "102 M     Total params\n",
      "409.378   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f02bc3c399943aa8596fd7c9d9f8a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c35738f3de4622b6b437a054aa9b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/09/2021 13:56:28 - INFO - openue.data.utils -   Loading features from cached file ./dataset/ske/cached_train_BertTokenizerFast_seq\n"
     ]
    }
   ],
   "source": [
    "parser = _setup_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "path = \"./config/run_seq.yaml\"\n",
    "# 使用config.yaml 载入超参设置\n",
    "opt = yaml.load(open(path))\n",
    "args.__dict__.update(opt)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "data_class = _import_class(f\"openue.data.{args.data_class}\")\n",
    "model_class = _import_class(f\"openue.models.{args.model_class}\")\n",
    "litmodel_class = _import_class(f\"openue.lit_models.{args.litmodel_class}\")\n",
    "\n",
    "data = data_class(args)\n",
    "\n",
    "lit_model = litmodel_class(args=args, data_config=data.get_config())\n",
    "\n",
    "\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "if args.wandb:\n",
    "    logger = pl.loggers.WandbLogger(project=\"openue demo\")\n",
    "    logger.log_hyperparams(vars(args))\n",
    "\n",
    "early_callback = pl.callbacks.EarlyStopping(monitor=\"Eval/f1\", mode=\"max\", patience=5)\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"Eval/f1\", mode=\"max\",\n",
    "    filename='{epoch}-{Eval/f1:.2f}',\n",
    "    dirpath=\"output\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [early_callback, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, logger=logger, default_root_dir=\"training/logs\")\n",
    "\n",
    "trainer.fit(lit_model, datamodule=data)\n",
    "\n",
    "trainer.test(lit_model, datamodule=data)\n",
    "\n",
    "\n",
    "_save_model(litmodel=lit_model, tokenizer=data.tokenizer, path=\"seq_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实体识别模块\n",
    "\n",
    "在训练过程中，我们利用golden标签进行实体识别，即假设已经获得句子中存在的关系，之后利用这些关系来进行实体识别。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = _setup_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "path = \"./config/run_ner.yaml\"\n",
    "# 使用config.yaml 载入超参设置\n",
    "opt = yaml.load(open(path))\n",
    "args.__dict__.update(opt)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "data_class = _import_class(f\"openue.data.{args.data_class}\")\n",
    "model_class = _import_class(f\"openue.models.{args.model_class}\")\n",
    "litmodel_class = _import_class(f\"openue.lit_models.{args.litmodel_class}\")\n",
    "\n",
    "data = data_class(args)\n",
    "\n",
    "lit_model = litmodel_class(args=args, data_config=data.get_config())\n",
    "\n",
    "\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "if args.wandb:\n",
    "    logger = pl.loggers.WandbLogger(project=\"openue demo\")\n",
    "    logger.log_hyperparams(vars(args))\n",
    "\n",
    "early_callback = pl.callbacks.EarlyStopping(monitor=\"Eval/f1\", mode=\"max\", patience=5)\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"Eval/f1\", mode=\"max\",\n",
    "    filename='{epoch}-{Eval/f1:.2f}',\n",
    "    dirpath=\"output\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [early_callback, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, logger=logger, default_root_dir=\"training/logs\")\n",
    "\n",
    "trainer.fit(lit_model, datamodule=data)\n",
    "\n",
    "trainer.test(lit_model, datamodule=data)\n",
    "_save_model(litmodel=lit_model, tokenizer=data.tokenizer, path=\"ner_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证\n",
    "\n",
    "由于我们使用pipeline模型，所以无法联合训练，需要分别训练后进行统一验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = _setup_parser()\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "path = \"./config/run_inter.yaml\"\n",
    "# 使用config.yaml 载入超参设置\n",
    "opt = yaml.load(open(path))\n",
    "args.__dict__.update(opt)\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "data_class = _import_class(f\"openue.data.{args.data_class}\")\n",
    "model_class = _import_class(f\"openue.models.{args.model_class}\")\n",
    "litmodel_class = _import_class(f\"openue.lit_models.{args.litmodel_class}\")\n",
    "\n",
    "data = data_class(args)\n",
    "\n",
    "lit_model = litmodel_class(args=args, data_config=data.get_config())\n",
    "\n",
    "\n",
    "\n",
    "logger = pl.loggers.TensorBoardLogger(\"training/logs\")\n",
    "if args.wandb:\n",
    "    logger = pl.loggers.WandbLogger(project=\"openue demo\")\n",
    "    logger.log_hyperparams(vars(args))\n",
    "\n",
    "early_callback = pl.callbacks.EarlyStopping(monitor=\"Eval/f1\", mode=\"max\", patience=5)\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"Eval/f1\", mode=\"max\",\n",
    "    filename='{epoch}-{Eval/f1:.2f}',\n",
    "    dirpath=\"output\",\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [early_callback, model_checkpoint]\n",
    "\n",
    "trainer = pl.Trainer.from_argparse_args(args, callbacks=callbacks, logger=logger, default_root_dir=\"training/logs\")\n",
    "\n",
    "if \"inter\" not in path :trainer.fit(lit_model, datamodule=data)\n",
    "\n",
    "trainer.test(lit_model, datamodule=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ee29d4c65a463677a56f7e718e0fe6afedbb1a78c06a034d94d3fcc7a37838e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('py38': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
